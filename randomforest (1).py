# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p94GZ9PcvjdvsLde5Z3uzBGCNSgGfTWm
"""

import pandas as pd
from sklearn import tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

#reading the dataset
df = pd.read_csv("clean_used_cars.csv")

#defining Y and removing outliers
df = df[df['price'] > 0]

q1 = df['price'].quantile(0.25)
q3 = df['price'].quantile(0.75)
iqr = q3 - q1
upper_bound = q3 + (1.5 * iqr)
lower_bound = q1 - (1.5 * iqr)
df = df[df['price'] <= upper_bound]
df = df[df['price'] >= lower_bound]


df['price_log'] = np.log(df['price'])
Y = df['price_log']

#dividing the features by category or numerical
categorical_features = ["brand", "fuel_type", "transmission_type", "model"]   # <-- ADDED brand here
numerical_features = ["model_year", "mileage", "clean_title"]

#defining X by combining all features
X = df[categorical_features + numerical_features]

#encoding categorical values
preprocessor = ColumnTransformer(transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features),
        ("num", "passthrough", numerical_features),
])

#splitiing the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)

#offically encoding values
x_train_encoded = preprocessor.fit_transform(X_train)
x_test_encoded = preprocessor.transform(X_test)

#finish the decision tree model
model = tree.DecisionTreeRegressor(max_depth=10, random_state=42)
model.fit(x_train_encoded, Y_train)

#predicting the test set using the model
Y_prediction = model.predict(x_test_encoded)

#evaluating the model
mse = mean_squared_error(np.exp(Y_test), np.exp(Y_prediction))
r2 = r2_score(Y_test, Y_prediction)

print(f"Singular Decision Tree RMSE: {np.sqrt(mse):,.2f}")
print(f"Singular Decision Tree R^2: {r2:.4f}")

#finish the random forest tree model
model2 = RandomForestRegressor(n_estimators=200, max_depth=None, random_state=42, n_jobs=-1)
model2.fit(x_train_encoded, Y_train)

#predicting the test set using the model
Y_prediction2 = model2.predict(x_test_encoded)

#evaluating the model
mse2 = mean_squared_error(np.exp(Y_test), np.exp(Y_prediction2))
r22 = r2_score(np.exp(Y_test), np.exp(Y_prediction2))

print(f"Random Forest Decision Tree RMSE: {np.sqrt(mse2):,.2f}")
print(f"Random Forest Decision Tree R^2: {r22:.4f}")